{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import torchvision.transforms.functional as F  # Add this line to import 'F'\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 64,kernel_size= 4, stride = 2, padding = 1 , padding_mode='reflect'),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=4,stride=2,padding=1,padding_mode='reflect'),\n",
    "            nn.InstanceNorm2d(num_features = 128),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=4,stride=2,padding=1,padding_mode='reflect'),\n",
    "            nn.InstanceNorm2d(num_features = 256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256,out_channels=512,kernel_size=4,stride=1,padding=1,padding_mode='reflect'),\n",
    "            nn.InstanceNorm2d(num_features = 512),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.block5 = nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4,stride=1,padding=1,padding_mode = 'reflect')\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        return torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self, numResiduals):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initial convolutional layer\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 64,kernel_size= 7, stride = 1, padding = 3 , padding_mode='reflect'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.down2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.down3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.residuals = nn.Sequential()\n",
    "        for i in range(numResiduals):\n",
    "            self.residuals.add_module(f\"residual_block_{i}\", nn.Sequential(\n",
    "                nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size=3, padding=1, padding_mode=\"reflect\"),\n",
    "                nn.InstanceNorm2d(256),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size=3, padding=1, padding_mode=\"reflect\"),\n",
    "                nn.InstanceNorm2d(256),\n",
    "            ))\n",
    "\n",
    "       \n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels = 256, out_channels = 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels = 128, out_channels = 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "       \n",
    "        self.up3 = nn.Conv2d(in_channels = 64,out_channels = 3,kernel_size=7,stride=1,padding=3,padding_mode=\"reflect\",)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.down1(x)\n",
    "        x = self.down2(x)\n",
    "        x = self.down3(x)\n",
    "        x = self.residuals(x) + x  \n",
    "        x = self.up1(x)\n",
    "        x = self.up2(x)\n",
    "        x =self.up3(x)\n",
    "        return torch.tanh(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class dataSetMaps(Dataset):\n",
    "    def __init__(self,aerialDirectory,mapDirectory):\n",
    "        self.aerialDirectory = aerialDirectory\n",
    "        self.mapDirectory = mapDirectory\n",
    "        self.transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(256, 256)),\n",
    "    #transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "        \n",
    "        \n",
    "        self.aerialImages = os.listdir(aerialDirectory)\n",
    "        self.mapImages  = os.listdir(mapDirectory)\n",
    "        self.length = max(len(self.aerialImages), len(self.mapImages))\n",
    "        self.aerialLength = len(self.aerialImages)\n",
    "        self.mapLength = len(self.mapImages)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        mapImage = self.mapImages[index]\n",
    "        aerialImage = self.aerialImages[index]\n",
    "        \n",
    "        \n",
    "        mapPath = os.path.join(self.mapDirectory, mapImage)\n",
    "        aerialPath = os.path.join(self.aerialDirectory, aerialImage)\n",
    "        \n",
    "        \n",
    "        mapImage = (Image.open(mapPath).convert(\"RGB\"))\n",
    "        aerialImage = (Image.open(aerialPath).convert(\"RGB\"))\n",
    "        \n",
    "        if torch.rand(1) < 0.5:  \n",
    "            aerialImage  = F.hflip(aerialImage)\n",
    "            mapImage  = F.hflip(mapImage)\n",
    "            \n",
    "        aerialImage  = self.transforms(aerialImage)\n",
    "        mapImage  = self.transforms(mapImage)\n",
    "        #aerialImage  = np.array(aerialImage)\n",
    "        #mapImage  = np.array(mapImage)\n",
    "        \n",
    "        return  mapImage,aerialImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "def trainingFunction(mapDiscriminator, aerialDiscriminator, mapGenerator, aerialGenerator, \n",
    "                     DiscriminatorOptimiser, GeneratorOptimiser, l1Loss, meanSquareError, \n",
    "                     dataSet, loader, cycleLambda, savePath, epoch, saveInterval=10):\n",
    "    loop = tqdm(loader, leave=False)\n",
    "    \n",
    "    for index, (mapImage, aerialImage) in enumerate(loop):\n",
    "        mapImage = mapImage.to(device)\n",
    "        aerialImage = aerialImage.to(device)\n",
    "\n",
    "        # Train Discriminators\n",
    "        fakeMap = mapGenerator(mapImage)\n",
    "        disRealMap = mapDiscriminator(mapImage)\n",
    "        disFakeMap = mapDiscriminator(fakeMap.detach())\n",
    "        disRealMapLoss = meanSquareError(disRealMap, torch.ones_like(disRealMap))\n",
    "        disFakeMapLoss = meanSquareError(disFakeMap, torch.zeros_like(disFakeMap))\n",
    "        disMapTotalLoss = disRealMapLoss + disFakeMapLoss\n",
    "\n",
    "        fakeAerial = aerialGenerator(mapImage)\n",
    "        disRealAerial = aerialDiscriminator(aerialImage)\n",
    "        disFakeAerial = aerialDiscriminator(fakeAerial.detach())\n",
    "        disRealAerialLoss = meanSquareError(disRealAerial, torch.ones_like(disRealAerial))\n",
    "        disFakeAerialLoss = meanSquareError(disFakeAerial, torch.zeros_like(disFakeAerial))\n",
    "        disAerialTotalLoss = disRealAerialLoss + disFakeAerialLoss\n",
    "\n",
    "        discriminatorLoss = (disAerialTotalLoss + disMapTotalLoss) / 2\n",
    "\n",
    "        DiscriminatorOptimiser.zero_grad()\n",
    "        discriminatorLoss.backward()\n",
    "        DiscriminatorOptimiser.step()\n",
    "\n",
    "        # Train Generators\n",
    "        disFakeMap = mapDiscriminator(fakeMap)\n",
    "        disFakeAerial = aerialDiscriminator(fakeAerial)\n",
    "        disRealAerialLoss = meanSquareError(disFakeAerial, torch.ones_like(disFakeAerial))\n",
    "        disRealMapLoss = meanSquareError(disFakeMap, torch.ones_like(disFakeMap))\n",
    "\n",
    "        cycleMap = mapGenerator(fakeAerial)\n",
    "        cycleAerial = aerialGenerator(fakeMap)\n",
    "        cycleMapLoss = l1Loss(mapImage, cycleMap)\n",
    "        cycleAerialLoss = l1Loss(aerialImage, cycleAerial)\n",
    "\n",
    "        generatorLoss = (disRealAerialLoss + disRealMapLoss +\n",
    "                         (cycleMapLoss * cycleLambda) + (cycleAerialLoss * cycleLambda))\n",
    "        \n",
    "        GeneratorOptimiser.zero_grad()\n",
    "        generatorLoss.backward()\n",
    "        GeneratorOptimiser.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        if not os.path.exists(savePath):\n",
    "            os.makedirs(savePath)\n",
    "        \n",
    "        torch.save({\n",
    "            'mapGenerator_state_dict': mapGenerator.state_dict(),\n",
    "            'aerialGenerator_state_dict': aerialGenerator.state_dict(),\n",
    "            'mapDiscriminator_state_dict': mapDiscriminator.state_dict(),\n",
    "            'aerialDiscriminator_state_dict': aerialDiscriminator.state_dict(),\n",
    "            'generator_optimizer_state_dict': GeneratorOptimiser.state_dict(),\n",
    "            'discriminator_optimizer_state_dict': DiscriminatorOptimiser.state_dict(),\n",
    "            'epoch': epoch\n",
    "        }, os.path.join(savePath, f'model_epoch_{epoch}.pth'))\n",
    "        \n",
    "        print(f'Models saved at epoch {epoch}.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapDiscriminator = discriminator().to(device)\n",
    "aerialDiscriminator = discriminator().to(device)\n",
    "\n",
    "mapGenerator  = generator(9).to(device)\n",
    "aerialGenerator = generator(9).to(device)\n",
    "\n",
    "DiscriminatorOptimiser = optim.Adam(list(mapDiscriminator.parameters()) + list(aerialDiscriminator.parameters()), lr =  1e-5, betas = (0.5,0.99))\n",
    "\n",
    "GeneratorOptimiser = optim.Adam(list(mapDiscriminator.parameters()) + list(aerialDiscriminator.parameters()), lr =  1e-5, betas = (0.5,0.99))\n",
    "\n",
    "l1Loss = nn.L1Loss()\n",
    "meanSquareError = nn.MSELoss()\n",
    "\n",
    "dataSet = dataSetMaps('mapscycle/dataset/aerialTrain', 'mapscycle/dataset/mapTrain')\n",
    "loader = DataLoader(dataSet, batch_size = 4, shuffle = True, num_workers = 2, pin_memory = True)\n",
    "\n",
    "cycleLambda =10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "for i in range(epochs):\n",
    "    \n",
    "    trainingFunction(mapDiscriminator,aerialDiscriminator, mapGenerator, aerialGenerator, DiscriminatorOptimiser, GeneratorOptimiser, l1Loss, meanSquareError, dataSet, loader, cycleLambda,'modelVersions',10,i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "dataSet = dataSetMaps('mapscycle/dataset/aerialVal', '/mapscycle/dataset/mapVal')\n",
    "testLoader = DataLoader(dataSet, batch_size=1, shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "def testFunction(mapGenerator, aerialGenerator, testLoader, maxImages=5):\n",
    "    mapGenerator.eval()\n",
    "    aerialGenerator.eval()\n",
    "    \n",
    "    iouValuesMapToAerial = []\n",
    "    iouValuesAerialToMap = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index, (mapImage, aerialImage) in enumerate(testLoader):\n",
    "            mapImage = mapImage.to(device)\n",
    "            aerialImage = aerialImage.to(device)\n",
    "\n",
    "            generatedAerial = mapGenerator(mapImage)\n",
    "            iouMapToAerial = calculateIou(generatedAerial, aerialImage)\n",
    "            iouValuesMapToAerial.append(iouMapToAerial)\n",
    "\n",
    "            generatedMap = aerialGenerator(aerialImage)\n",
    "            iouAerialToMap = calculateIou(generatedMap, mapImage)\n",
    "            iouValuesAerialToMap.append(iouAerialToMap)\n",
    "\n",
    "   \n",
    "\n",
    "    avgIouMapToAerial = sum(iouValuesMapToAerial) / len(iouValuesMapToAerial)\n",
    "    avgIouAerialToMap = sum(iouValuesAerialToMap) / len(iouValuesAerialToMap)\n",
    "    \n",
    "    print(f\"Average IoU (Map to Aerial): {avgIouMapToAerial}\")\n",
    "    print(f\"Average IoU (Aerial to Map): {avgIouAerialToMap}\")\n",
    "\n",
    "def showImages(mapImage, aerialImage, generatedAerial, generatedMap):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "    mapImage = mapImage.cpu().squeeze(0).permute(1, 2, 0) * 0.5 + 0.5\n",
    "    aerialImage = aerialImage.cpu().squeeze(0).permute(1, 2, 0) * 0.5 + 0.5\n",
    "    generatedAerial = generatedAerial.cpu().squeeze(0).permute(1, 2, 0) * 0.5 + 0.5\n",
    "    generatedMap = generatedMap.cpu().squeeze(0).permute(1, 2, 0) * 0.5 + 0.5\n",
    "\n",
    "    axes[0, 0].imshow(mapImage)\n",
    "    axes[0, 0].set_title('Original Map')\n",
    "    axes[0, 0].axis('off')\n",
    "\n",
    " \n",
    "    axes[0, 1].imshow(aerialImage)\n",
    "    axes[0, 1].set_title('Original Aerial')\n",
    "    axes[0, 1].axis('off')\n",
    "\n",
    "    axes[0, 2].imshow(generatedAerial)\n",
    "    axes[0, 2].set_title('Generated Aerial')\n",
    "    axes[0, 2].axis('off')\n",
    "\n",
    "    axes[1, 0].imshow(generatedMap)\n",
    "    axes[1, 0].set_title('Generated Map')\n",
    "    axes[1, 0].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def calculateIou(generated, real):\n",
    "    threshold = 0.5\n",
    "    generatedMask = (generated > threshold).int().cpu().numpy().flatten()\n",
    "    realMask = (real > threshold).int().cpu().numpy().flatten()\n",
    "\n",
    "    iou = jaccard_score(realMask, generatedMask, average='binary')\n",
    "    return iou\n",
    "\n",
    "testFunction(mapGenerator, aerialGenerator, testLoader, maxImages=5)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
