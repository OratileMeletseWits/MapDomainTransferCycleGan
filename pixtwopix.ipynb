{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9610541,"sourceType":"datasetVersion","datasetId":5864167}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#[64,128,256,512]\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.block1 = nn.Sequential(\n            #in channel is 6 since we are concat the two types\n            nn.Conv2d(in_channels=6,out_channels=64, kernel_size=4,stride=2,padding = 1, padding_mode='reflect'),\n            nn.LeakyReLU(0.2),\n        )\n        self.block2 = nn.Sequential(\n            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=4,stride=2,padding=1,padding_mode='reflect'),\n            nn.BatchNorm2d(num_features = 128),\n            nn.LeakyReLU(0.2)\n        )\n        self.block3 = nn.Sequential(\n            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=4,stride=2,padding=1,padding_mode='reflect'),\n            nn.BatchNorm2d(num_features = 256),\n            nn.LeakyReLU(0.2)\n        )\n        self.block4 = nn.Sequential(\n            nn.Conv2d(in_channels=256,out_channels=512,kernel_size=4,stride=1,padding=1,padding_mode='reflect'),\n            nn.BatchNorm2d(num_features = 512),\n            nn.LeakyReLU(0.2)\n        )\n        self.block5 = nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4,stride=1,padding=1,padding_mode='reflect')\n    #x is input , y is our out put (fake or real)\n    def forward(self,x,y):\n        x = torch.cat([x,y], dim =1) # dim zero is ||, dim one is channels, we are concat channels\n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        x = self.block4(x)\n        x = self.block5(x)\n        return x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.down1 = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=4, stride=2,padding = 1, padding_mode='reflect'),\n            nn.LeakyReLU(0.2),\n        )\n        self.down2 = nn.Sequential(\n            nn.Conv2d(in_channels=64 ,out_channels=128, kernel_size=4, stride=2,padding = 1, padding_mode='reflect'),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2),\n                      \n        )\n        self.down3 = nn.Sequential(\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2,padding = 1, padding_mode='reflect'),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2),\n                      \n        )\n        self.down4 = nn.Sequential(\n            nn.Conv2d(in_channels=256 ,out_channels=512, kernel_size=4, stride=2,padding = 1, padding_mode='reflect'),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2),\n                      \n        )\n        self.down5 = nn.Sequential(\n            nn.Conv2d(in_channels=512 ,out_channels=512, kernel_size=4, stride=2,padding = 1, padding_mode='reflect'),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2),\n                      \n        )\n        self.down6 = nn.Sequential(\n            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4, stride=2,padding = 1, padding_mode='reflect'),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2),\n                      \n        )\n        self.down7 = nn.Sequential(\n            nn.Conv2d(in_channels=512 ,out_channels=512, kernel_size=4, stride=2,padding = 1, padding_mode='reflect'),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2),\n                      \n        )\n\n        self.bottleNeck = nn.Sequential(\n            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=4, stride=2,padding = 1, padding_mode='reflect'),\n            nn.ReLU()\n        )\n        self.dropOut = nn.Dropout(0.5)\n\n        self.up1 = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU()\n            #dropout\n            \n        )\n        self.up2 = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU()\n            #dropout\n            \n        )\n        self.up3 = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU()\n            #dropout\n            \n        )\n        self.up4 = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=4, stride=2,padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU()\n          \n            \n        )\n        self.up5 = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=1024, out_channels=256, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU()\n          \n            \n        )\n        self.up6 = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=512, out_channels=128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU()\n          \n            \n        )\n        self.up7 = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=256, out_channels=64, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU()\n          \n            \n        )\n        self.out = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=128, out_channels=3, kernel_size=4, stride=2, padding=1),\n            nn.Tanh()\n            \n        )\n\n    def forward(self,x):\n        d1 = self.down1(x)\n        d2 = self.down2(d1)\n        d3 = self.down3(d2)\n        d4 = self.down4(d3)\n        d5 = self.down5(d4)\n        d6 = self.down6(d5)\n        d7 = self.down7(d6)\n        bottleneck = self.bottleNeck(d7)\n\n        u1 = self.up1(bottleneck)\n        u1 =self.dropOut(u1)\n        u2 = self.up2(torch.cat([u1,d7],1))\n        u2 =self.dropOut(u2)\n        u3 = self.up3(torch.cat([u2,d6],1))\n        u3 = self.dropOut(u3)\n        u4 = self.up4(torch.cat([u3,d5],1))\n        u5 = self.up5(torch.cat([u4,d4],1))\n        u6 = self.up6(torch.cat([u5,d3],1))\n        u7 = self.up7(torch.cat([u6,d2],1))\n        output = self.out(torch.cat([u7,d1],1))\n        return output","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torchvision.transforms import v2\nfrom PIL import Image\nimport os\nimport numpy as np\nimport torchvision.transforms as transforms\nimport torchvision.transforms.functional as F\n\ntransform = transforms.Compose([\n    transforms.Resize(size=(256, 256)),\n    #transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ToTensor(),  \n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\nclass mapDataSet():\n    def __init__(self, directory):\n        self.directory = directory\n        self.listImages = os.listdir(self.directory)\n        #self.transform = transforms \n\n    def __len__(self):\n        return len(self.listImages)\n\n    def __getitem__(self, index):\n      \n        imageFile = self.listImages[index]\n        imagePath = os.path.join(self.directory, imageFile)\n        image = Image.open(imagePath)  \n        width, height = image.size\n        \n        inputImage = image.crop((0, 0, width // 2, height))  \n        targetImage = image.crop((width // 2, 0, width, height))  \n\n        if torch.rand(1) < 0.5:  \n            inputImage = F.hflip(inputImage)\n            targetImage = F.hflip(targetImage)\n        \n        inputImage = transform(inputImage)\n        targetImage = transform(targetImage)\n\n        return inputImage, targetImage\n\n        \n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef trainingFunction(generator, discriminator, trainingLoader, optimisorDiscriminator, optimisorGenerator, l1Loss, binaryCrossEntropy, l1Lambda,epoch):\n    loop = tqdm(trainingLoader, leave = True)\n    if (epoch + 1) % 10 == 0:\n        saveDirectory = '/kaggle/working/'\n        os.makedirs(saveDirectory, exist_ok=True)\n        \n        generator_path = os.path.join(saveDirectory, f'generator{epoch}.pth')\n        discriminator_path = os.path.join(saveDirectory, f'discriminator{epoch}.pth')\n        \n        torch.save(generator.state_dict(), generator_path)\n        torch.save(discriminator.state_dict(), discriminator_path)\n        \n        print(f'Models saved at epoch {epoch + 1}')\n\n    for index, (x,y) in enumerate(loop):\n        x = x.to(device)\n        y = y.to(device)\n\n        yGenerated = generator(x)\n        dReal = discriminator(x,y)\n        dFake = discriminator(x, yGenerated.detach()) #loss.backward(retain_grapg = True)\n        discriminatorRealLoss  = binaryCrossEntropy(dReal, torch.ones_like(dReal))\n        discriminatorFakeLoss  = binaryCrossEntropy(dFake, torch.ones_like(dFake))\n        discriminatorLoss = (discriminatorFakeLoss + discriminatorRealLoss) / 2 # paper, experiment with no devision\n\n    discriminator.zero_grad()\n    discriminatorLoss.backward()\n    optimisorDiscriminator.step()\n\n\n    dFake = discriminator(x, yGenerated.detach())\n    generatorFakeLoss = binaryCrossEntropy(dFake, torch.ones_like(dFake))\n    l1 = l1Loss(yGenerated, y) + l1Lambda\n    generatorLoss = generatorFakeLoss + l1\n\n    generator.zero_grad()\n    generatorLoss.backward()\n    optimisorGenerator.step()\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ngenerator = Generator().to(device)\ndiscriminator =  Discriminator().to(device)\noptimisorDiscriminator = optim.Adam(discriminator.parameters(), lr = 2e-4, betas = (0.5,0.999))\noptimisorGenerator = optim.Adam(generator.parameters() , lr = 2e-4, betas = (0.5, 0.999))\nbinaryCrossEntropy = nn.BCEWithLogitsLoss()\nl1Loss = nn.L1Loss()\nl1Lambda = 100\n\ntrainingDataSet = mapDataSet('/kaggle/input/mapdataset/maps/train')\ntestDataSet = mapDataSet('/kaggle/input/mapdataset/maps/val')\ntrainingLoader = DataLoader(trainingDataSet, batch_size = 4, shuffle = True, num_workers = 1)\ntestLoader = DataLoader(testDataSet, batch_size = 1, shuffle = False, num_workers = 1)\nepochs = 15\nfor i in range(epochs):\n\n    trainingFunction(generator, discriminator, trainingLoader, optimisorDiscriminator, optimisorGenerator, l1Loss, binaryCrossEntropy, l1Lambda,i+101)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''import torch\nimport os\n\ndef loadModelOnly(generator, discriminator, saveDirectory):\n    generatorPath = os.path.join(saveDirectory, 'generator.pth')\n    discriminatorPath = os.path.join(saveDirectory, 'discriminator.pth')\n    \n    if os.path.exists(generatorPath) and os.path.exists(discriminatorPath):\n        generator.load_state_dict(torch.load(generatorPath))\n        discriminator.load_state_dict(torch.load(discriminatorPath))\n    \n\ndef trainingFunctionCont(generator, discriminator, trainingLoader, optimisorDiscriminator, optimisorGenerator, l1Loss, binaryCrossEntropy, l1Lambda, epoch, saveDirectory='/kaggle/working/'):\n    loop = tqdm(trainingLoader, leave=False)\n    \n    if (epoch + 1) % 10 == 0:\n        os.makedirs(saveDirectory, exist_ok=True)\n        \n        generator_path = os.path.join(saveDirectory, 'generator.pth')\n        discriminator_path = os.path.join(saveDirectory, 'discriminator.pth')\n        \n        torch.save(generator.state_dict(), generator_path)\n        torch.save(discriminator.state_dict(), discriminator_path)\n        \n        print(f'Models saved at epoch {epoch + 1}')\n\n    \n    for index, (x, y) in enumerate(loop):\n        x = x.to(device)\n        y = y.to(device)\n\n        yGenerated = generator(x)\n        \n        dReal = discriminator(x, y)\n        dFake = discriminator(x, yGenerated.detach())  # Detach to avoid updating the generator\n        discriminatorRealLoss  = binaryCrossEntropy(dReal, torch.ones_like(dReal))\n        discriminatorFakeLoss  = binaryCrossEntropy(dFake, torch.zeros_like(dFake))\n        discriminatorLoss = (discriminatorFakeLoss + discriminatorRealLoss) / 2\n\n        discriminator.zero_grad()\n        discriminatorLoss.backward()\n        optimisorDiscriminator.step()\n\n        dFake = discriminator(x, yGenerated)\n        generatorFakeLoss = binaryCrossEntropy(dFake, torch.ones_like(dFake))\n        l1 = l1Loss(yGenerated, y) * l1Lambda\n        generatorLoss = generatorFakeLoss + l1\n\n        generator.zero_grad()\n        generatorLoss.backward()\n        optimisorGenerator.step()\n\nsaveDirectory = '/kaggle/working/'\nloadModelOnly(generator, discriminator, saveDirectory)\nepochs = 0\nfor i in range(epochs):\n    trainingFunctionCont(generator, discriminator, trainingLoader, optimisorDiscriminator, optimisorGenerator, l1Loss, binaryCrossEntropy, l1Lambda, i, saveDirectory)\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torchvision.transforms.functional as F\nimport torch\nimport torchmetrics\nfrom sklearn.metrics import jaccard_score\n\n\n\ndef testFunction(generator, testLoader, l1Loss, maxImages=5):\n    generator.eval() \n    iouValues = []\n    maxImages = 0\n    maxNeed 5\n    with torch.no_grad():\n        for index, (mapImage, aerialImage) in enumerate(testLoader):\n            mapImage = mapImage.to(device)\n            aerialImage = aerialImage.to(device)\n\n            generatedAerial = generator(mapImage)\n\n           \n            iouValue = calculateIou(generatedAerial, aerialImage)\n            iouValues.append(iouValue)\n            \n            showImages(mapImage, aerialImage, generatedAerial)\n            maxImages+=1\n            if(maxImages == maxNeed):\n                break\n            \n\n  \n    avgIou = sum(iouValues) / len(iouValues)\n    print(f\"Average IoU: {avgIou}\")\n    generator.train() \n    \n\ndef showImages(mapImage, aerialImage, generatedAerial):\n    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n\n    mapImage = mapImage.cpu().squeeze(0).permute(1, 2, 0) * 0.5 + 0.5  # unnormalize\n    aerialImage = aerialImage.cpu().squeeze(0).permute(1, 2, 0) * 0.5 + 0.5  # unnormalize\n    generatedAerial = generatedAerial.cpu().squeeze(0).permute(1, 2, 0) * 0.5 + 0.5  # unnormalize\n    \n    axes[0].imshow(mapImage)\n    axes[0].set_title('Original Aerial')\n    axes[0].axis('off')\n\n    # Display the original aerial image\n    axes[1].imshow(aerialImage)\n    axes[1].set_title('Original Map')\n    axes[1].axis('off')\n\n    # Display the generated aerial image\n    axes[2].imshow(generatedAerial)\n    axes[2].set_title('Generated Map')\n    axes[2].axis('off')\n\n    plt.show()\n\ndef calculateIou(generated, real):\n    threshold = 0.5\n    generatedMask = (generated > threshold).int().cpu().numpy().flatten()\n    realMask = (real > threshold).int().cpu().numpy().flatten()\n\n    iou = jaccard_score(realMask, generatedMask, average='binary')\n    return iou\n\ntestFunction(generator, testLoader, l1Loss, maxImages=5)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = 5\nfor i in range(epochs):\n\n    trainingFunction(generator, discriminator, trainingLoader, optimisorDiscriminator, optimisorGenerator, l1Loss, binaryCrossEntropy, l1Lambda,i+101)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"testFunction(generator, testLoader, l1Loss, maxImages=5)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = 300\nfor i in range(epochs):\n\n    trainingFunction(generator, discriminator, trainingLoader, optimisorDiscriminator, optimisorGenerator, l1Loss, binaryCrossEntropy, l1Lambda,i+101)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"testFunction(generator, testLoader, l1Loss, maxImages=5)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torchvision\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torchvision import transforms\nimport math\nfrom torchvision.metrics import structural_similarity_index_measure as ssim\n\ndef calculate_psnr(generated, target):\n    mse = F.mse_loss(generated, target)\n    if mse == 0:\n        return float('inf')\n    return 20 * math.log10(1.0 / math.sqrt(mse))  # Assuming images are normalized to [0, 1]\n\ndef testFunction(generator, testLoader, l1Loss, maxImages=5):\n    generator.eval()\n    iouValues = []\n    psnrValues = []\n    ssimValues = []\n    maxImages = 0\n\n    with torch.no_grad():\n        for index, (mapImage, aerialImage) in enumerate(testLoader):\n            mapImage = mapImage.to(device)\n            aerialImage = aerialImage.to(device)\n\n            generatedAerial = generator(mapImage)\n\n            # Calculate IoU\n            iouValue = calculateIou(generatedAerial, aerialImage)\n            iouValues.append(iouValue)\n\n            # Calculate PSNR\n            psnrValue = calculate_psnr(generatedAerial, aerialImage)\n            psnrValues.append(psnrValue)\n\n            # Calculate SSIM\n            ssimValue = ssim(generatedAerial, aerialImage)\n            ssimValues.append(ssimValue)\n\n            # Show the images\n            if maxImages < 5:\n                showImages(mapImage, aerialImage, generatedAerial)\n                maxImages += 1\n\n    # Compute the average metrics\n    avgIou = sum(iouValues) / len(iouValues)\n    avgPsnr = sum(psnrValues) / len(psnrValues)\n    avgSsim = sum(ssimValues) / len(ssimValues)\n\n    # Print results\n    print(f\"Average IoU: {avgIou}\")\n    print(f\"Average PSNR: {avgPsnr}\")\n    print(f\"Average SSIM: {avgSsim}\")\n\n    generator.train()\nmaxImages = 5\n(generator, testLoader, l1Loss,maxImages)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}